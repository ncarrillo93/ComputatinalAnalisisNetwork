{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3-final"
    },
    "colab": {
      "name": "Trabajo_1_con_python.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "source": [
        "# Tarea 1\n",
        "## Nicolás Carrillo Sepúlveda\n",
        "\n",
        "\n",
        "### 1. Simulación de redes sociales\n",
        "Utilizando los archivos de redes en Campus Virtual, realizar un estudio de la simulación por medio de redes Erdös-Rényi, Watts.\n",
        "-Strogatz, Newman-Watts-Strogatz. Se pide realizar una tabla similar a la pág 11 en la presentación en clase calculando \n",
        "el número de nodos, el grado promedio y los coeficientes de clusterización. Determinar el mejor modelo para cada ejemplo."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZcI2iCxn17n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e305f0d6-8f33-4536-d53c-ce75c104f6e2"
      },
      "source": [
        "import networkx as nx\n",
        "from tabulate import tabulate\n",
        "citas = nx.read_edgelist(\"Redes_datos/citas_bibliograficas.txt\")\n",
        "redB = nx.read_edgelist(\"Redes_datos/red_biologica.txt\",delimiter=\",\")\n",
        "emails = nx.read_edgelist(\"Redes_datos/emails.txt\",delimiter=\" \")\n",
        "\n",
        "n_citas  = nx.number_of_nodes(citas)\n",
        "n_redB   = nx.number_of_nodes(redB)\n",
        "n_emails = nx.number_of_nodes(emails)\n",
        "\n",
        "p=0.9\n",
        "seed=123\n",
        "\n",
        "k_citas  = round((sum(deg for n_citas  ,deg in nx.degree(citas)) / n_citas))\n",
        "k_redB   = round((sum(deg for n_redB   ,deg in nx.degree(citas)) / n_redB))\n",
        "k_emails = round((sum(deg for n_emails ,deg in nx.degree(citas)) / n_emails))\n",
        "\n",
        "citas_ER  = nx.erdos_renyi_graph(n_citas,p,seed,directed=False)\n",
        "citas_WS  = nx.watts_strogatz_graph(n_citas,k_citas,p,seed)\n",
        "citas_NWS = nx.newman_watts_strogatz_graph(n_citas,k_citas,p,seed)\n",
        "\n",
        "redB_ER  = nx.erdos_renyi_graph(n_redB,p,seed,directed=False)\n",
        "redB_WS  = nx.watts_strogatz_graph(n_redB,k_redB,p,seed)\n",
        "redB_NWS = nx.newman_watts_strogatz_graph(n_redB,k_redB,p,seed)\n",
        "\n",
        "emails_ER  = nx.erdos_renyi_graph(n_emails,p,seed,directed=False)\n",
        "emails_WS  = nx.watts_strogatz_graph(n_emails,k_emails,p,seed)\n",
        "emails_NWS = nx.newman_watts_strogatz_graph(n_emails,k_emails,p,seed)\n",
        "\n",
        "table=[]\n",
        "table.append(['Citas Bibliograficas',nx.number_of_nodes(citas),\n",
        "                                    nx.average_clustering(citas_ER),\n",
        "                                    nx.average_clustering(citas_WS),\n",
        "                                    nx.average_clustering(citas_NWS),\n",
        "                                    nx.average_clustering(citas)])\n",
        "table.append(['Red Biologica',nx.number_of_nodes(redB),\n",
        "                              nx.average_clustering(redB_ER),\n",
        "                              nx.average_clustering(redB_WS),\n",
        "                              nx.average_clustering(redB_NWS),\n",
        "                              nx.average_clustering(redB)])\n",
        "table.append(['Emails',nx.number_of_nodes(emails),\n",
        "                       nx.average_clustering(emails_ER),\n",
        "                       nx.average_clustering(emails_WS),\n",
        "                       nx.average_clustering(emails_NWS),\n",
        "                       nx.average_clustering(emails)])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph                    n      C-ER        C-WS     C-NWS    C_actual\n--------------------  ----  --------  ----------  --------  ----------\nCitas Bibliograficas  5242  0.900108  0.00143316  0.164137   0.529636\nRed Biologica         1450  0.899917  0.0135961   0.210759   0.0382951\nEmails                1005  0.899788  0.0275338   0.229229   0.399355\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(tabulate(table,headers = ['Graph', 'n','C-ER','C-WS','C-NWS','C_actual']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ka3QS4UvR3XJ"
      },
      "source": [
        "\n",
        "### 2. Contagio en redes\n",
        "#### - Utilice uno de los archivos Facebook de mayor número de nodos que pueda ejecutar en us computador. Se pide simular el contagio de una enfermedad tipo SIR en la red. Para ello vamos a considerar un tiempo $T$ de iteraciones del modelo y los parámetros $\\beta$, $\\gamma$, $N$ número de vecinos infectados. Para simplificar el problema, fijaremos la tasa de recuperados en $\\gamma=0.8$  \n",
        "#### 1. Definir el estado inicial de cada nodo (Sano, Infectado) considerando un random de infectados de proporción $\\beta$.\n",
        "#### 2. Determinar el contagio en base al número $N$ de vecinos infectados.\n",
        "#### 3. En base a los contagiados, recuperar $\\gamma$ de ellos de manera random.\n",
        "#### 4. Calcular la proporción de sanos, infectados, recuperados y almacenar.\n",
        "#### 5. Graficar los resultados después de $T=100$ iteraciones.\n",
        "Considere los escenarios $\\beta=0.1,0.2,0.3$ y $N=1,2,3,5$. ¿En qué escenarios se logra erradicar la enfermedad?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nr1qfEtASIbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "3dd5ded1-684c-4e45-f400-12a86459b799"
      },
      "source": [
        "import networkx as nx\n",
        "import matplotlib.pyplot as plot\n",
        "import ndlib.models.ModelConfig as mc\n",
        "import ndlib.models.epidemics as ep\n",
        "from ndlib.viz.bokeh.DiffusionTrend import DiffusionTrend\n",
        "from ndlib.viz.bokeh.MultiPlot import MultiPlot\n",
        "\n",
        "Facebook1 = nx.read_edgelist(\"Facebook_reducido/Facebook4000.txt\")\n",
        "model = ep.SIRModel(Facebook1)\n",
        "\n",
        "b = [0.1 , 0.2 , 0.3]\n",
        "N = [1 , 2 , 3 , 5 ]\n",
        "gamma = 0.8\n",
        "T = 8 #100\n",
        "viz = 0\n",
        "mp = MultiPlot()\n",
        "for beta in b:\n",
        "    for Ns in N:\n",
        "        f_infectados = Ns/nx.number_of_nodes(Facebook1)\n",
        "        config = mc.Configuration()\n",
        "        config.add_model_parameter('beta',beta)\n",
        "        config.add_model_parameter('gamma',gamma)\n",
        "        config.add_model_parameter('f_infectados',f_infectados)\n",
        "        model.set_initial_status(config)\n",
        "\n",
        "        iteraciones = model.iteration_bunch(T)\n",
        "        trends = model.build_trends(iteraciones)\n",
        "        viz = DiffusionTrend(model, trends)\n",
        "        mp.add_plot(viz.plot(width=600, height=400))\n",
        "        model.get_info()\n",
        "        model.reset()\n",
        "graficos = mp.plot()\n",
        "show(graficos)\n"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:00<00:00, 52.90it/s]\n",
            "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
            "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
            "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
            "100%|██████████| 8/8 [00:00<00:00, 54.07it/s]\n",
            "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
            "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
            "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
            "100%|██████████| 8/8 [00:00<00:00, 47.08it/s]\n",
            "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
            "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
            "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
            "100%|██████████| 8/8 [00:00<00:00, 53.08it/s]\n",
            "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
            "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
            "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
            "100%|██████████| 8/8 [00:00<00:00, 56.31it/s]\n",
            "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
            "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
            "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
            "100%|██████████| 8/8 [00:00<00:00, 54.77it/s]\n",
            "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
            "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
            "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
            "100%|██████████| 8/8 [00:00<00:00, 51.70it/s]\n",
            "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
            "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
            "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
            "100%|██████████| 8/8 [00:00<00:00, 57.16it/s]\n",
            "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
            "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
            "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
            "100%|██████████| 8/8 [00:00<00:00, 57.94it/s]\n",
            "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
            "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
            "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
            "100%|██████████| 8/8 [00:00<00:00, 60.62it/s]\n",
            "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
            "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
            "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
            "100%|██████████| 8/8 [00:00<00:00, 58.90it/s]\n",
            "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
            "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
            "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
            "100%|██████████| 8/8 [00:00<00:00, 55.58it/s]\n",
            "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
            "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
            "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IRzSYy4R-DM"
      },
      "source": [
        "\n",
        "### Bonus: Programar el modelo SIS y ajustar los parámetros a los datos de contagio del covid-19 $\\beta,\\gamma$ y estimar $N$ para simular la propagación en redes del virus.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "output_type": "error",
          "ename": "ConfigurationException",
          "evalue": "{'message': 'Missing mandatory model parameter(s)', 'parameters': {'lambda'}}",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mConfigurationException\u001b[0m                    Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-82-5a615ed4ce94>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_model_parameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'gamma'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_model_parameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'f_infectados'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mf_infectados\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_initial_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0miteraciones\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miteration_bunch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ndlib\\models\\DiffusionModel.py\u001b[0m in \u001b[0;36mset_initial_status\u001b[1;34m(self, configuration)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \"\"\"\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__validate_configuration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfiguration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[0mnodes_cfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfiguration\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_nodes_configuration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ndlib\\models\\DiffusionModel.py\u001b[0m in \u001b[0;36m__validate_configuration\u001b[1;34m(self, configuration)\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0momp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0momp\u001b[0m \u001b[1;33m&\u001b[0m \u001b[0mmdp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0momp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mConfigurationException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"message\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"Missing mandatory model parameter(s)\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"parameters\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0momp\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mmdp\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0monp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mConfigurationException\u001b[0m: {'message': 'Missing mandatory model parameter(s)', 'parameters': {'lambda'}}"
          ]
        }
      ],
      "source": [
        "import networkx as nx\n",
        "import matplotlib.pyplot as plot\n",
        "import ndlib.models.ModelConfig as mc\n",
        "import ndlib.models.epidemics as ep\n",
        "from ndlib.viz.bokeh.DiffusionTrend import DiffusionTrend\n",
        "from ndlib.viz.bokeh.MultiPlot import MultiPlot\n",
        "\n",
        "Facebook1 = nx.read_edgelist(\"Facebook_reducido/Facebook4000.txt\")\n",
        "model = ep.SISModel(Facebook1)\n",
        "\n",
        "#buscar valores para beta, gamma y N\n",
        "b = 0.01\n",
        "N = 5\n",
        "gamma = 0.08\n",
        "T = 100\n",
        "\n",
        "f_infectados = N/nx.number_of_nodes(Facebook1)\n",
        "config = mc.Configuration()\n",
        "config.add_model_parameter('beta',b)\n",
        "config.add_model_parameter('gamma',gamma)\n",
        "config.add_model_parameter('f_infectados',f_infectados)\n",
        "model.set_initial_status(config)\n",
        "\n",
        "iteraciones = model.iteration_bunch(T)\n",
        "trends = model.build_trends(iteraciones)\n",
        "viz = DiffusionTrend(model, trends)\n",
        "p = viz.plot(width=600,height=400)\n",
        "show(p)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeHZlOYDSAqA"
      },
      "source": [
        "### 3. Marketing viral\n",
        "#### Nuevamente utilizamos el archivo Facebook de mayor tamaño. Similar al caso anterior, definiremos un conjunto inicia de recomendadores de dos maneras: random con proporciones 0.1, 0.2 y el 10% y 20% de los nodos más influyentes (mayores grados).\n",
        "#### 1. Definir el estado de cada nodo en Influencer y No influencer.\n",
        "#### 2. crear un grafo dirigido de las influencias en base a $N=2,3,5$ recomendaciones y hacer la dinámica hasta que no queden nodos por influenciar. Considerar un 10% y 20%  de influenciados que cambian de estado.\n",
        "### 3. En base a cada grafo dirigido, encontrar las cascadas más comunes.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zbxXqAbSJVh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqkAwAWISCc3"
      },
      "source": [
        "\n",
        "### 4. Ley de potencia\n",
        "#### Utilizando los archivos de redes, \n",
        "#### 1. Ajustar la potencia para modelar la distribución de grados de cada ejemplo\n",
        "#### 2. Averiguar sobre las redes de Barabási-Albert para modelar grafos del de potencia\n",
        "#### 3. Ajustar un grafo de Barabási-Albert para cada modelo calibrando el parámetro de arcos nuevos\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjZ2N44NSKC6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtDUy2YNSEcR"
      },
      "source": [
        "### Bonus: leer y comentar el artículo \n",
        "Scale-free networks are rare, Anna D. Broido & Aaron Clauset, Nature Communications volume 10, Article number: 1017 (2019)\n",
        "https://www.nature.com/articles/s41467-019-08746-5\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlsCBD99SKmv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}